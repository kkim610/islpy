{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Stock Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume', 'Today',\n",
      "       'Direction_Up'],\n",
      "      dtype='object')\n",
      "(1250, 9)\n",
      "              Year         Lag1         Lag2         Lag3         Lag4  \\\n",
      "count  1250.000000  1250.000000  1250.000000  1250.000000  1250.000000   \n",
      "mean   2003.016000     0.003834     0.003919     0.001716     0.001636   \n",
      "std       1.409018     1.136299     1.136280     1.138703     1.138774   \n",
      "min    2001.000000    -4.922000    -4.922000    -4.922000    -4.922000   \n",
      "25%    2002.000000    -0.639500    -0.639500    -0.640000    -0.640000   \n",
      "50%    2003.000000     0.039000     0.039000     0.038500     0.038500   \n",
      "75%    2004.000000     0.596750     0.596750     0.596750     0.596750   \n",
      "max    2005.000000     5.733000     5.733000     5.733000     5.733000   \n",
      "\n",
      "             Lag5       Volume        Today  Direction_Up  \n",
      "count  1250.00000  1250.000000  1250.000000   1250.000000  \n",
      "mean      0.00561     1.478305     0.003138      0.518400  \n",
      "std       1.14755     0.360357     1.136334      0.499861  \n",
      "min      -4.92200     0.356070    -4.922000      0.000000  \n",
      "25%      -0.64000     1.257400    -0.639500      0.000000  \n",
      "50%       0.03850     1.422950     0.038500      1.000000  \n",
      "75%       0.59700     1.641675     0.596750      1.000000  \n",
      "max       5.73300     3.152470     5.733000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "smarket = pd.read_csv('../../data/Smarket.csv', index_col=0)\n",
    "direc_orig = smarket['Direction'].values\n",
    "smarket = pd.get_dummies(smarket, drop_first=True)\n",
    "print(smarket.columns)\n",
    "print(smarket.shape)\n",
    "print(smarket.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction_Up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.030596</td>\n",
       "      <td>0.033195</td>\n",
       "      <td>0.035689</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.539006</td>\n",
       "      <td>0.030095</td>\n",
       "      <td>0.074608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag1</th>\n",
       "      <td>0.029700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026294</td>\n",
       "      <td>-0.010803</td>\n",
       "      <td>-0.002986</td>\n",
       "      <td>-0.005675</td>\n",
       "      <td>0.040910</td>\n",
       "      <td>-0.026155</td>\n",
       "      <td>-0.039757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag2</th>\n",
       "      <td>0.030596</td>\n",
       "      <td>-0.026294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025897</td>\n",
       "      <td>-0.010854</td>\n",
       "      <td>-0.003558</td>\n",
       "      <td>-0.043383</td>\n",
       "      <td>-0.010250</td>\n",
       "      <td>-0.024081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag3</th>\n",
       "      <td>0.033195</td>\n",
       "      <td>-0.010803</td>\n",
       "      <td>-0.025897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.024051</td>\n",
       "      <td>-0.018808</td>\n",
       "      <td>-0.041824</td>\n",
       "      <td>-0.002448</td>\n",
       "      <td>0.006132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag4</th>\n",
       "      <td>0.035689</td>\n",
       "      <td>-0.002986</td>\n",
       "      <td>-0.010854</td>\n",
       "      <td>-0.024051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.027084</td>\n",
       "      <td>-0.048414</td>\n",
       "      <td>-0.006900</td>\n",
       "      <td>0.004215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag5</th>\n",
       "      <td>0.029788</td>\n",
       "      <td>-0.005675</td>\n",
       "      <td>-0.003558</td>\n",
       "      <td>-0.018808</td>\n",
       "      <td>-0.027084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022002</td>\n",
       "      <td>-0.034860</td>\n",
       "      <td>0.005423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>0.539006</td>\n",
       "      <td>0.040910</td>\n",
       "      <td>-0.043383</td>\n",
       "      <td>-0.041824</td>\n",
       "      <td>-0.048414</td>\n",
       "      <td>-0.022002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014592</td>\n",
       "      <td>0.022951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Today</th>\n",
       "      <td>0.030095</td>\n",
       "      <td>-0.026155</td>\n",
       "      <td>-0.010250</td>\n",
       "      <td>-0.002448</td>\n",
       "      <td>-0.006900</td>\n",
       "      <td>-0.034860</td>\n",
       "      <td>0.014592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Direction_Up</th>\n",
       "      <td>0.074608</td>\n",
       "      <td>-0.039757</td>\n",
       "      <td>-0.024081</td>\n",
       "      <td>0.006132</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.022951</td>\n",
       "      <td>0.730563</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Year      Lag1      Lag2      Lag3      Lag4      Lag5  \\\n",
       "Year          1.000000  0.029700  0.030596  0.033195  0.035689  0.029788   \n",
       "Lag1          0.029700  1.000000 -0.026294 -0.010803 -0.002986 -0.005675   \n",
       "Lag2          0.030596 -0.026294  1.000000 -0.025897 -0.010854 -0.003558   \n",
       "Lag3          0.033195 -0.010803 -0.025897  1.000000 -0.024051 -0.018808   \n",
       "Lag4          0.035689 -0.002986 -0.010854 -0.024051  1.000000 -0.027084   \n",
       "Lag5          0.029788 -0.005675 -0.003558 -0.018808 -0.027084  1.000000   \n",
       "Volume        0.539006  0.040910 -0.043383 -0.041824 -0.048414 -0.022002   \n",
       "Today         0.030095 -0.026155 -0.010250 -0.002448 -0.006900 -0.034860   \n",
       "Direction_Up  0.074608 -0.039757 -0.024081  0.006132  0.004215  0.005423   \n",
       "\n",
       "                Volume     Today  Direction_Up  \n",
       "Year          0.539006  0.030095      0.074608  \n",
       "Lag1          0.040910 -0.026155     -0.039757  \n",
       "Lag2         -0.043383 -0.010250     -0.024081  \n",
       "Lag3         -0.041824 -0.002448      0.006132  \n",
       "Lag4         -0.048414 -0.006900      0.004215  \n",
       "Lag5         -0.022002 -0.034860      0.005423  \n",
       "Volume        1.000000  0.014592      0.022951  \n",
       "Today         0.014592  1.000000      0.730563  \n",
       "Direction_Up  0.022951  0.730563      1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smarket.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD3CAYAAAAALt/WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEESOQ4KcIAgix/n/vOhuNXTVDHUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b3becf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smarket['Volume'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691034\n",
      "         Iterations 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>Direction_Up</td>   <th>  No. Observations:  </th>  <td>  1250</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  1243</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 25 Oct 2017</td> <th>  Pseudo R-squ.:     </th> <td>0.002074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:50:42</td>     <th>  Log-Likelihood:    </th> <td> -863.79</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -865.59</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.7319</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.1260</td> <td>    0.241</td> <td>   -0.523</td> <td> 0.601</td> <td>   -0.598</td> <td>    0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag1</th>      <td>   -0.0731</td> <td>    0.050</td> <td>   -1.457</td> <td> 0.145</td> <td>   -0.171</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag2</th>      <td>   -0.0423</td> <td>    0.050</td> <td>   -0.845</td> <td> 0.398</td> <td>   -0.140</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag3</th>      <td>    0.0111</td> <td>    0.050</td> <td>    0.222</td> <td> 0.824</td> <td>   -0.087</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag4</th>      <td>    0.0094</td> <td>    0.050</td> <td>    0.187</td> <td> 0.851</td> <td>   -0.089</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag5</th>      <td>    0.0103</td> <td>    0.050</td> <td>    0.208</td> <td> 0.835</td> <td>   -0.087</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Volume</th>    <td>    0.1354</td> <td>    0.158</td> <td>    0.855</td> <td> 0.392</td> <td>   -0.175</td> <td>    0.446</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:           Direction_Up   No. Observations:                 1250\n",
       "Model:                          Logit   Df Residuals:                     1243\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Wed, 25 Oct 2017   Pseudo R-squ.:                0.002074\n",
       "Time:                        11:50:42   Log-Likelihood:                -863.79\n",
       "converged:                       True   LL-Null:                       -865.59\n",
       "                                        LLR p-value:                    0.7319\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.1260      0.241     -0.523      0.601      -0.598       0.346\n",
       "Lag1          -0.0731      0.050     -1.457      0.145      -0.171       0.025\n",
       "Lag2          -0.0423      0.050     -0.845      0.398      -0.140       0.056\n",
       "Lag3           0.0111      0.050      0.222      0.824      -0.087       0.109\n",
       "Lag4           0.0094      0.050      0.187      0.851      -0.089       0.107\n",
       "Lag5           0.0103      0.050      0.208      0.835      -0.087       0.107\n",
       "Volume         0.1354      0.158      0.855      0.392      -0.175       0.446\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direc_logit = smf.logit('Direction_Up ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume', smarket).fit()\n",
    "direc_logit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept   -0.126000\n",
       "Lag1        -0.073074\n",
       "Lag2        -0.042301\n",
       "Lag3         0.011085\n",
       "Lag4         0.009359\n",
       "Lag5         0.010313\n",
       "Volume       0.135441\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direc_logit.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    0.600700\n",
       "Lag1         0.145232\n",
       "Lag2         0.398352\n",
       "Lag3         0.824334\n",
       "Lag4         0.851445\n",
       "Lag5         0.834998\n",
       "Volume       0.392404\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direc_logit.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50708413,  0.48146788,  0.48113883,  0.51522236,  0.51078116,\n",
       "        0.50695646,  0.49265087,  0.50922916,  0.51761353,  0.48883778])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = direc_logit.predict()\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Up', 'Down', 'Down', 'Up', 'Up', 'Up', 'Down', 'Up', 'Up', 'Down'],\n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direc_pred = np.array(['Down']*1250)\n",
    "direc_pred[y_pred > 0.5] = 'Up'\n",
    "direc_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[145, 457],\n",
       "       [141, 507]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(direc_orig, direc_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  Down   Up\n",
      "Actual              \n",
      "Down        145  457\n",
      "Up          141  507\n"
     ]
    }
   ],
   "source": [
    "#alternative with better labels\n",
    "y_cm = pd.DataFrame({'Actual': direc_orig, 'Predicted': direc_pred})\n",
    "cm = pd.crosstab(y_cm['Actual'], y_cm['Predicted'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691936\n",
      "         Iterations 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>Direction_Up</td>   <th>  No. Observations:  </th>  <td>   998</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   991</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 25 Oct 2017</td> <th>  Pseudo R-squ.:     </th> <td>0.001562</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:50:42</td>     <th>  Log-Likelihood:    </th> <td> -690.55</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -691.63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.9044</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.1912</td> <td>    0.334</td> <td>    0.573</td> <td> 0.567</td> <td>   -0.463</td> <td>    0.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag1</th>      <td>   -0.0542</td> <td>    0.052</td> <td>   -1.046</td> <td> 0.295</td> <td>   -0.156</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag2</th>      <td>   -0.0458</td> <td>    0.052</td> <td>   -0.884</td> <td> 0.377</td> <td>   -0.147</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag3</th>      <td>    0.0072</td> <td>    0.052</td> <td>    0.139</td> <td> 0.889</td> <td>   -0.094</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag4</th>      <td>    0.0064</td> <td>    0.052</td> <td>    0.125</td> <td> 0.901</td> <td>   -0.095</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag5</th>      <td>   -0.0042</td> <td>    0.051</td> <td>   -0.083</td> <td> 0.934</td> <td>   -0.104</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Volume</th>    <td>   -0.1163</td> <td>    0.240</td> <td>   -0.485</td> <td> 0.628</td> <td>   -0.586</td> <td>    0.353</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:           Direction_Up   No. Observations:                  998\n",
       "Model:                          Logit   Df Residuals:                      991\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Wed, 25 Oct 2017   Pseudo R-squ.:                0.001562\n",
       "Time:                        11:50:42   Log-Likelihood:                -690.55\n",
       "converged:                       True   LL-Null:                       -691.63\n",
       "                                        LLR p-value:                    0.9044\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.1912      0.334      0.573      0.567      -0.463       0.845\n",
       "Lag1          -0.0542      0.052     -1.046      0.295      -0.156       0.047\n",
       "Lag2          -0.0458      0.052     -0.884      0.377      -0.147       0.056\n",
       "Lag3           0.0072      0.052      0.139      0.889      -0.094       0.108\n",
       "Lag4           0.0064      0.052      0.125      0.901      -0.095       0.108\n",
       "Lag5          -0.0042      0.051     -0.083      0.934      -0.104       0.096\n",
       "Volume        -0.1163      0.240     -0.485      0.628      -0.586       0.353\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smarket = pd.read_csv('../../data/Smarket.csv', index_col=0)\n",
    "#split the dataset into train (<= 2004) and test (2005)\n",
    "smarket_train = smarket[smarket['Year'] <= 2004].copy()\n",
    "smarket_test = smarket[smarket['Year'] > 2004].copy()\n",
    "#get the Up and Down labels before making dummies\n",
    "direc_train = smarket_train['Direction']\n",
    "direc_test = smarket_test['Direction']\n",
    "#make the dummies for Direction\n",
    "smarket_train = pd.get_dummies(smarket_train, drop_first=True)\n",
    "smarket_test = pd.get_dummies(smarket_test, drop_first=True)\n",
    "#perform multiple logistic regression on training data\n",
    "smarket_logit = smf.logit('Direction_Up ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume', smarket_train).fit()\n",
    "smarket_logit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77, 34],\n",
       "       [97, 44]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make predictions on test data\n",
    "y_pred = smarket_logit.predict(exog=smarket_test)\n",
    "#convert test predictions for Direction to Up (> 0.5) and Down (<= 0.5)\n",
    "direc_pred = np.array(['Down'] * len(y_pred))\n",
    "direc_pred[y_pred > 0.5] = 'Up'\n",
    "#make the confusion matrix\n",
    "cm = confusion_matrix(direc_test, direc_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Correct Rate: 0.48\n",
      "Test Error Rate: 0.52\n"
     ]
    }
   ],
   "source": [
    "#print the corret rate and error rate for test predictions\n",
    "print('Test Correct Rate: {:.2f}'.format((direc_test == direc_pred).mean()))\n",
    "print('Test Error Rate: {:.2f}'.format((direc_test != direc_pred).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692085\n",
      "         Iterations 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>Direction_Up</td>   <th>  No. Observations:  </th>  <td>   998</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 25 Oct 2017</td> <th>  Pseudo R-squ.:     </th> <td>0.001347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:50:42</td>     <th>  Log-Likelihood:    </th> <td> -690.70</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -691.63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.3939</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.0322</td> <td>    0.063</td> <td>    0.508</td> <td> 0.611</td> <td>   -0.092</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag1</th>      <td>   -0.0556</td> <td>    0.052</td> <td>   -1.076</td> <td> 0.282</td> <td>   -0.157</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag2</th>      <td>   -0.0445</td> <td>    0.052</td> <td>   -0.861</td> <td> 0.389</td> <td>   -0.146</td> <td>    0.057</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:           Direction_Up   No. Observations:                  998\n",
       "Model:                          Logit   Df Residuals:                      995\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Wed, 25 Oct 2017   Pseudo R-squ.:                0.001347\n",
       "Time:                        11:50:42   Log-Likelihood:                -690.70\n",
       "converged:                       True   LL-Null:                       -691.63\n",
       "                                        LLR p-value:                    0.3939\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.0322      0.063      0.508      0.611      -0.092       0.156\n",
       "Lag1          -0.0556      0.052     -1.076      0.282      -0.157       0.046\n",
       "Lag2          -0.0445      0.052     -0.861      0.389      -0.146       0.057\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model with less predictors\n",
    "smarket_logit = smf.logit('Direction_Up ~ Lag1 + Lag2', smarket_train).fit()\n",
    "smarket_logit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35,  76],\n",
       "       [ 35, 106]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make predictions on test data\n",
    "y_pred = smarket_logit.predict(exog=smarket_test)\n",
    "#convert test predictions for Direction to Up (> 0.5) and Down (<= 0.5)\n",
    "direc_pred = np.array(['Down'] * len(y_pred))\n",
    "direc_pred[y_pred > 0.5] = 'Up'\n",
    "#make the confusion matrix\n",
    "cm = confusion_matrix(direc_test, direc_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Correct Rate: 0.56\n",
      "Test Error Rate: 0.44\n",
      "Accuracy: 0.582\n"
     ]
    }
   ],
   "source": [
    "#print the corret rate and error rate for test predictions\n",
    "print('Test Correct Rate: {:.2f}'.format((direc_test == direc_pred).mean()))\n",
    "print('Test Error Rate: {:.2f}'.format((direc_test != direc_pred).mean()))\n",
    "print('Accuracy: {:.3f}'.format(cm[1, 1] / cm[:, 1].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.479146\n",
       "1    0.496094\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smarket_logit.predict(exog={'Lag1': [1.2, 1.5], 'Lag2': [1.1, -0.8]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "X_train = smarket_train[['Lag1', 'Lag2']].values\n",
    "X_test = smarket_test[['Lag1', 'Lag2']].values\n",
    "y_train = smarket_train['Direction_Up'].values\n",
    "y_test = smarket_test['Direction_Up'].values\n",
    "\n",
    "lda = LDA()\n",
    "lda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49198397,  0.50801603])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.priors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04279022,  0.03389409],\n",
       "       [-0.03954635, -0.03132544]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.64201904],\n",
       "       [-0.51352928]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.scalings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35,  76],\n",
       "       [ 35, 106]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lda.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Correct Rate: 0.56\n"
     ]
    }
   ],
   "source": [
    "print('Test Correct Rate: {:.2f}'.format((y_test == y_pred).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Up: 182\n",
      "Predicted Down: 70\n"
     ]
    }
   ],
   "source": [
    "post_pred = lda.predict_proba(X_test)\n",
    "#the first column of post_pred is predicting class 0 (Direction = Down)\n",
    "#Here's how they do it in the book but I don't like it\n",
    "#print((post_pred[:, 0] >= 0.5).sum())\n",
    "#print((post_pred[:, 0] < 0.5).sum())\n",
    "\n",
    "#the second column of post_pred is predicting class 1 (Direction = Up)\n",
    "#it makes much more sense for me to do it this way\n",
    "print('Predicted Up: {}'.format((post_pred[:, 1] >= 0.5).sum()))\n",
    "print('Predicted Down: {}'.format((post_pred[:, 1] < 0.5).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.49017925  0.50982075]\n",
      " [ 0.4792185   0.5207815 ]\n",
      " [ 0.46681848  0.53318152]\n",
      " [ 0.47400107  0.52599893]\n",
      " [ 0.49278766  0.50721234]\n",
      " [ 0.49385615  0.50614385]\n",
      " [ 0.49510156  0.50489844]\n",
      " [ 0.4872861   0.5127139 ]\n",
      " [ 0.49070135  0.50929865]\n",
      " [ 0.48440262  0.51559738]\n",
      " [ 0.49069628  0.50930372]\n",
      " [ 0.51199885  0.48800115]\n",
      " [ 0.48951523  0.51048477]\n",
      " [ 0.47067612  0.52932388]\n",
      " [ 0.47445929  0.52554071]\n",
      " [ 0.47995834  0.52004166]\n",
      " [ 0.49357753  0.50642247]\n",
      " [ 0.50308938  0.49691062]\n",
      " [ 0.49788061  0.50211939]\n",
      " [ 0.48863309  0.51136691]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(post_pred[:20, :])\n",
    "print(y_pred[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Up with 90% threshold: 0\n"
     ]
    }
   ],
   "source": [
    "print('Predicted Up with 90% threshold: {}'.format((post_pred[:, 1] >= 0.9).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "               store_covariances=False, tol=0.0001)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49198397,  0.50801603])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda.priors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04279022,  0.03389409],\n",
       "       [-0.03954635, -0.03132544]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30,  81],\n",
       "       [ 20, 121]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = qda.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.599\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.3f}'.format((y_pred == y_test).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "knn = KNN(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43 68]\n",
      " [58 83]]\n",
      "Accuracy: 0.500\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: {:.3f}'.format((y_pred == y_test).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNN(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48 63]\n",
      " [55 86]]\n",
      "Accuracy: 0.532\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: {:.3f}'.format((y_pred == y_test).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Application on Caravan Insurance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     5822\n",
       "unique       2\n",
       "top         No\n",
       "freq      5474\n",
       "Name: Purchase, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caravan = pd.read_csv('../../data/Caravan.csv', index_col=0)\n",
    "caravan['Purchase'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05977327378907592"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5822 - 5474)/5822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = caravan[caravan.columns[:-1]].values\n",
    "y = caravan['Purchase'].values\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cols 1 and 2 Before Scaling: 165.0378 and 0.1647\n",
      "Cols 1 and 2 After Scaling: 1.0000 and 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Cols 1 and 2 Before Scaling: {:.4f} and {:.4f}'.format(caravan[caravan.columns[0]].var(), \n",
    "                                                  caravan[caravan.columns[1]].var()))\n",
    "print('Cols 1 and 2 After Scaling: {:.4f} and {:.4f}'.format(X[:, 0].var(), X[:, 1].var()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.118\n",
      "0.059\n"
     ]
    }
   ],
   "source": [
    "X_test = X[:1000, :]\n",
    "X_train = X[1000:, :]\n",
    "y_test = y[:1000]\n",
    "y_train = y[1000:]\n",
    "\n",
    "knn = KNN(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print((y_test != y_pred).mean())\n",
    "print((y_test != 'No').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[873  68]\n",
      " [ 50   9]]\n",
      "0.116883116883\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(cm[1, 1] / cm[:, 1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[921  20]\n",
      " [ 54   5]]\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "knn = KNN(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(cm[1, 1] / cm[:, 1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[930  11]\n",
      " [ 55   4]]\n",
      "0.266666666667\n"
     ]
    }
   ],
   "source": [
    "knn = KNN(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(cm[1, 1] / cm[:, 1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[934   7]\n",
      " [ 59   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_proba = lr.predict_proba(X_test)\n",
    "y_pred = np.array(['Yes'] * len(y_proba))\n",
    "y_pred[y_proba[:, 1] < 0.25] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[917,  24],\n",
       "       [ 48,  11]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
