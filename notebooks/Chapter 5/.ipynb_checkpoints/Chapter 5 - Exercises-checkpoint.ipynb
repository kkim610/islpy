{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1**:  \n",
    "Use the following rules:  \n",
    "\n",
    "$$Var(X+Y) = Var(X) + Var(Y) + 2Cov(X, Y)$$  \n",
    "$$Var(cX) = c^2Var(X)$$  \n",
    "$$Cov(cX, Y) = Cov(X, cY) = cCov(X, Y)$$\n",
    "\n",
    "to transform $Var(\\alpha X + (1 - \\alpha)Y)$:  \n",
    "\n",
    "$$Var(\\alpha X+(1-\\alpha )Y)=Var(\\alpha X) + Var((1-\\alpha )Y) + 2Cov(\\alpha X, (1-\\alpha )Y)$$  \n",
    "\n",
    "$$=\\alpha^2Var(X) + (1-\\alpha)^2Var(Y) + 2\\alpha (1-\\alpha )Cov(X, Y)$$  \n",
    "\n",
    "$$=\\alpha^2\\sigma_X^2 + (1-\\alpha)^2\\sigma_Y^2 + 2(\\alpha - \\alpha^2)\\sigma_{XY}$$  \n",
    "\n",
    "To minimize $Var(\\alpha X + (1 - \\alpha)Y$, we take the first derivative w.r.t. $\\alpha$ and set it to zero  \n",
    "\n",
    "$$\\frac{d}{d\\alpha}Var(\\alpha X + (1 - \\alpha)Y) = 2 \\alpha \\sigma_X^2 - 2(1-\\alpha)\\sigma_Y^2 + 2(1-2\\alpha)\\sigma_{XY}=0$$  \n",
    "\n",
    "We can divide both sides by 2\n",
    "\n",
    "$$\\alpha\\sigma_X^2 - \\sigma_Y^2 + \\alpha\\sigma_Y^2+\\sigma_{XY} - 2\\alpha\\sigma_{XY} = 0$$\n",
    "\n",
    "Grouping terms with $\\alpha$ gives us  \n",
    "\n",
    "$$\\alpha(\\sigma_X^2 + \\sigma_Y^2 - 2\\sigma_{XY}) - \\sigma_Y^2 + \\sigma_{XY} = 0$$  \n",
    "\n",
    "$$\\alpha(\\sigma_X^2 + \\sigma_Y^2 - 2\\sigma_{XY}) = \\sigma_Y^2 - \\sigma_{XY}$$  \n",
    "\n",
    "Now solve for $\\alpha$  \n",
    "\n",
    "$$\\alpha = \\frac{\\sigma_Y^2 - \\sigma_{XY}}{\\sigma_X^2 + \\sigma_Y^2 - 2\\sigma_{XY}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 (a)**:  \n",
    "The probability is equal to not selecting that one observation out of all observations:  \n",
    "\n",
    "$$\\frac{n-1}{n}=1-\\frac{1}{n}$$  \n",
    "\n",
    "**2 (b)**:  \n",
    "Because the bootstrap uses replacement, the probability is the same as in **2 (a)**:  \n",
    "\n",
    "$$\\frac{n-1}{n}=1-\\frac{1}{n}$$  \n",
    "\n",
    "**2 (c)**:  \n",
    "Because the bootstrap samples with replacement, each observation has the same $1-\\frac{1}{n}$ probability of not equalling the $j$th observation. After $n$ selections, the probability of never selecting the $j$th observation is $(\\frac{n-1}{n})^n=(1-\\frac{1}{n})^n$  \n",
    "\n",
    "**2 (d)**:  \n",
    "The probability that the $j$th observation is **not** in the bootstrap, $Pr(out)$, is $(1-\\frac{1}{n})^n$. The probability that the $j$th observation is in the bootstrap, $Pr(in)$, is equal to $1-Pr(out)$:  \n",
    "\n",
    "$$Pr(in) = 1 - Pr(out) = 1 - (1 - \\frac{1}{n})^n = 1 - (1 - \\frac{1}{5})^5 = 0.6723 = 67.23\\%$$  \n",
    "\n",
    "**2 (e)**:  \n",
    "Following the same logic as **2 (d)**:  \n",
    "\n",
    "$$Pr(in) = 1 - Pr(out) = 1 - (1 - \\frac{1}{n})^n = 1 - (1 - \\frac{1}{100})^100 = 0.6340 = 63.40\\%$$  \n",
    "\n",
    "**2 (f)**:  \n",
    "\n",
    "$$Pr(in) = 1 - Pr(out) = 1 - (1 - \\frac{1}{n})^n = 1 - (1 - \\frac{1}{10000})^10000 = 0.6321 = 63.21\\%$$\n",
    "\n",
    "**2 (g)**:  \n",
    "$$Pr(in) = 1 - Pr(out) = 1 - (1 - \\frac{1}{n})^n = 1 - (1 - \\frac{1}{100000})^100000 = 0.6321 = 63.21\\%$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x109268358>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGPyS1DP/HzOZ4SpOdVnRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10770c160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.linspace(1, 100001, 1000000)\n",
    "y = 1 - (1 - 1/x)**x\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot quickly reaches an asymptote of about 63.2%  \n",
    "\n",
    "**2 (h)**:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.75%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "n = 100\n",
    "obs = np.arange(1, n+1)\n",
    "counter = 0\n",
    "for i in range(10000):\n",
    "    obs_rs = resample(obs)\n",
    "    if 4 in obs_rs:\n",
    "        counter += 1\n",
    "print('{:.2f}%'.format(counter / 10000 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very close to the results above. With more iterations of the loop, it would be even closer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 (a)**:  \n",
    "$k$-fold cross-validation works by taking $k$ random, non-overlapping splits, or folds, of the $n$ observations. The first fold serves as the validation set, while the remaining $k-1$ splits are used to fit the statistical learning method. The mean squared error is then computed for the validation set. This procedure is repeated $k$ times. The test error rate is estimated by averaging the $k$ resulting MSE estimates.  \n",
    "\n",
    "**3 (b)**:  \n",
    "\n",
    " **i.** $k$-fold CV has less variance but more bias than validation CV  \n",
    " \n",
    " **ii.** $k$-fold has more variance but less bias than LOOCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4**:  \n",
    "We can use the bootstrap method to sample with replacement from our dataset and estimate the $Y$'s from each sample. With the results of different $\\widehat{Y}$'s, we can then estimate the standard deviation of our prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 (a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "default = pd.read_csv('../../data/Default.csv', index_col=0)\n",
    "\n",
    "X = default[['balance', 'income']].values\n",
    "y = default['default'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "logit.fit(X, y)\n",
    "y_pred = logit.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 (b)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error rate: 3.28%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=5000, random_state=420)\n",
    "\n",
    "logit.fit(X_train, y_train)\n",
    "y_pred = logit.predict(X_test)\n",
    "\n",
    "print('Test error rate: {:.2f}%'.format((y_pred != y_test).sum() / len(y_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 (c)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error rate 0: 3.76%\n",
      "Test error rate 1: 3.22%\n",
      "Test error rate 2: 3.12%\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=5000, random_state=i)\n",
    "    logit.fit(X_train, y_train)\n",
    "    y_pred = logit.predict(X_test)\n",
    "    print('Test error rate {}: {:.2f}%'.format(i, (y_pred != y_test).sum() / len(y_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error rate predictions are all similar to the actual default rate of 3.33% but shows some variance on either side of the actual default rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 (d)**:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error rate: 3.36%\n"
     ]
    }
   ],
   "source": [
    "default2 = pd.get_dummies(default, drop_first=True)\n",
    "\n",
    "X = default2[['balance', 'income', 'student_Yes']].values\n",
    "y = default2['default_Yes']\n",
    "\n",
    "logit.fit(X, y)\n",
    "y_pred = logit.predict(X)\n",
    "\n",
    "print('Test error rate: {:.2f}%'.format((y_pred != y).sum() / len(y) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this is very close to the true default rate in the data set, it's not clear whether this is an improvement for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6 (a)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -11.5405</td> <td>    0.435</td> <td>  -26.544</td> <td> 0.000</td> <td>  -12.393</td> <td>  -10.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>    0.0056</td> <td>    0.000</td> <td>   24.835</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td> 2.081e-05</td> <td> 4.99e-06</td> <td>    4.174</td> <td> 0.000</td> <td>  1.1e-05</td> <td> 3.06e-05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default = pd.read_csv('../../data/Default.csv', index_col=0)\n",
    "default2 = pd.get_dummies(default, drop_first=True)\n",
    "\n",
    "smf.logit('default_Yes ~ balance + income', default2).fit().summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**6 (b)**: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def boot(default):#, index):\n",
    "    #default = default.iloc[index]\n",
    "    logit = smf.logit('default_Yes ~ balance + income', default).fit(disp=0)\n",
    "    return logit.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6 (c)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_coef = np.array([])\n",
    "inc_coef = np.array([])\n",
    "for i in range(100):\n",
    "    params = boot(resample(default2))\n",
    "    bal_coef = np.append(bal_coef, params['balance'])\n",
    "    inc_coef = np.append(inc_coef, params['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance:\n",
      "\tCoefficient: 0.0056\n",
      "\tStd. Error: 0.0002\n",
      "\n",
      "Income:\n",
      "\tCoefficient: 2.0693e-05\n",
      "\tStd. Error: 4.7433e-06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Balance:\\n\\tCoefficient: {:.4f}\\n\\tStd. Error: {:.4f}\\n' \\\n",
    "      .format(bal_coef.mean(), bal_coef.std()))\n",
    "print('Income:\\n\\tCoefficient: {:.4e}\\n\\tStd. Error: {:.4e}\\n' \\\n",
    "      .format(inc_coef.mean(), inc_coef.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6 (d)**:\n",
    "\n",
    "The estimated standard errors obtained by the two methods are very close.\n",
    "\n",
    "**7 (a)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [ 0.22039089]\n",
      "Coefficients: [[-0.03867021  0.06022514]]\n"
     ]
    }
   ],
   "source": [
    "weekly = pd.read_csv('../../data/Weekly.csv')\n",
    "weekly2 = pd.get_dummies(weekly, drop_first=True)\n",
    "\n",
    "X = weekly[['Lag1', 'Lag2']].values\n",
    "y = weekly['Direction']\n",
    "\n",
    "logit = LogisticRegression()\n",
    "logit.fit(X, y)\n",
    "print('Intercept: {}\\nCoefficients: {}'.format(logit.intercept_, logit.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7 (b)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Up\n",
      "Actual: Down\n"
     ]
    }
   ],
   "source": [
    "index = list(range(len(weekly2)))\n",
    "\n",
    "X_train, X_test = X[index[1:]], X[index[0]]\n",
    "y_train, y_test = y[index[1:]], y[index[0]]\n",
    "\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7 (c)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Up\n",
      "Actual: Down\n"
     ]
    }
   ],
   "source": [
    "y_pred = logit.predict(X_test.reshape(1, -1))\n",
    "\n",
    "print('Predicted: {}\\nActual: {}'.format(y_pred[0], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
