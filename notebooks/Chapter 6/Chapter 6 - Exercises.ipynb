{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptual  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 (a)**:  \n",
    "When performing best subset selection, the model with $k$ predictors is the model with the smallest *training* RSS among all $C_p^k$ models with $k$ predictors.  \n",
    "\n",
    "**1 (b)**:  \n",
    "This is difficult to answer. On one hand, best subset selection may have the smallest test RSS because it considers many more models than forward or backward selection. On the other hand, forward or backward selection may yield a model with smaller test RSS by sheer luck.  \n",
    "\n",
    "**1 (c)**:  \n",
    "\n",
    "  **i.** *True* - Once a variable is added to the model in forward selection, it stays there. So when selecting the $k+1$ variable which minimizes the RSS, the previously added variables from the $k$ variable model are already included (i.e. the predictors in the $k$ variable model are a subset of the predictors in the $k+1$-variable model).  \n",
    "  \n",
    "  **ii.** *True* - The model with $k$ predictors is obtained by removing a single variable from the $k+1$ model. So all the predictors in the $k$ variable model are contained in the $k+1$ variable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
